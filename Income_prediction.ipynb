{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdyNOEnOZ9Kx"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "input_size = 14\n",
        "output_size = 1 \n",
        "hidden_size_1 = int((input_size+output_size)/2)+1\n",
        "hidden_size_2 = int(hidden_size_1/2)\n",
        "epoch_size = 5\n",
        "batch_size = 200\n",
        "learning_rate = 1 "
      ],
      "metadata": {
        "id": "bI2Np3FFasjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_loc = \"/content/drive/MyDrive/Colab_Notebooks/US_Income_prediction/Train_data.data\"\n",
        "\n",
        "test_file_loc = \"/content/drive/MyDrive/Colab_Notebooks/US_Income_prediction/Test_data.test\"\n",
        "\n"
      ],
      "metadata": {
        "id": "rNwaMkWmTGPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "class census_dataset(Dataset):\n",
        "  def __init__(self,file_type):\n",
        "    #data loading\n",
        "    self.data = pd.read_csv(file_type)\n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "    #dataset[0]\n",
        "    row = self.data.iloc[index]\n",
        "    sample = {'age' : row[0], 'workclass': row[1], 'fnlwgt': row[2], 'education': row[3],'education_num': row[4],\n",
        "              'marital_status': row[5], 'occupation': row[6], 'relationship': row[7], 'race': row[8], 'sex': row[9],\n",
        "              'capital_gain': row[10],'capital_loss': row[11], 'hours_per_week': row[12], 'native_country': row[13], 'income': row[14]}\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    #len(dataset)\n",
        "    return len(self.data)\n",
        "\n",
        "  def __replace__(self,old_item,new_item):\n",
        "    new = self.pd.replace(old_item,new_item, inplace=True,regex=True)\n",
        "    return new"
      ],
      "metadata": {
        "id": "OLUY6W5jU2NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tarining_dataset = census_dataset(train_file_loc)\n",
        "\n",
        "test_dataset = census_dataset(test_file_loc)\n"
      ],
      "metadata": {
        "id": "jAVREegMMA1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=tarining_dataset,batch_size=batch_size,shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle = True)\n"
      ],
      "metadata": {
        "id": "88As9U9I7d_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #processing data\n",
        "def processing_data(dataframe):\n",
        "  dataframe = dataframe.replace(\" ?\",np.nan).dropna()\n",
        "  dataframe = dataframe.reset_index()\n",
        "  dataframe.age = dataframe.age/dataframe.age.max()\n",
        "  dataframe.workclass.replace(('Private', 'Self-emp-not-inc', 'Self-emp-inc', 'Federal-gov', 'Local-gov', 'State-gov', 'Without-pay', 'Never-worked'),(1,2,3,4,5,6,7,8), inplace=True,regex = True)\n",
        "  dataframe.workclass = dataframe.workclass/dataframe.workclass.max()\n",
        "  dataframe.education.replace(('Bachelors', 'Some-college', '11th', 'HS-grad', 'Prof-school', 'Assoc-acdm', 'Assoc-voc', '9th', '7th-8th', '12th', 'Masters', '1st-4th', '10th', 'Doctorate', '5th-6th', 'Preschool'),(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16), inplace=True,regex = True)\n",
        "  dataframe.education = dataframe.education/dataframe.education.max()\n",
        "  dataframe.marital_status.replace(('Married-civ-spouse', 'Divorced', 'Never-married', 'Separated', 'Widowed', 'Married-spouse-absent', 'Married-AF-spouse'),(1,2,3,4,5,6,7), inplace=True,regex = True)\n",
        "  dataframe.marital_status = dataframe.marital_status/dataframe.marital_status.max()\n",
        "  dataframe.occupation.replace(('Tech-support', 'Craft-repair', 'Other-service', 'Sales', 'Exec-managerial', 'Prof-specialty', 'Handlers-cleaners', 'Machine-op-inspct', 'Adm-clerical', 'Farming-fishing', 'Transport-moving', 'Priv-house-serv', 'Protective-serv', 'Armed-Forces'),(1,2,3,4,5,6,7,8,9,10,11,12,13,14), inplace=True,regex = True)\n",
        "  dataframe.occupation = dataframe.occupation/dataframe.occupation.max()\n",
        "  dataframe.relationship.replace(('Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'),(1,2,3,4,5,6), inplace=True,regex = True)\n",
        "  dataframe.relationship = dataframe.relationship/dataframe.relationship.max()\n",
        "  dataframe.race.replace(('White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'),(1,2,3,4,5), inplace=True,regex = True)\n",
        "  dataframe.race = dataframe.race/dataframe.race.max()\n",
        "  dataframe.sex.replace(('Female', 'Male'),(1,2), inplace=True,regex = True)\n",
        "  dataframe.native_country.replace((\"Outlying-US(Guam-USVI-etc)\", \"Cambodia\", \"England\", \"Puerto-Rico\", \"Canada\", \"Germany\", \"United-States\", \"India\", \"Japan\", \"Greece\", \"South\", \"China\", \"Cuba\", \"Iran\", \"Honduras\", \"Philippines\", \"Italy\", \"Poland\", \"Jamaica\", \"Vietnam\", \"Mexico\", \"Portugal\", \"Ireland\", \"France\", \"Dominican-Republic\", \"Laos\", \"Ecuador\", \"Taiwan\", \"Haiti\", \"Columbia\", \"Hungary\", \"Guatemala\", \"Nicaragua\", \"Scotland\", \"Thailand\", \"Yugoslavia\", \"El-Salvador\", \"Trinadad&Tobago\", \"Peru\", \"Hong\", \"Holand-Netherlands\"),(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41), inplace=True,regex = True)\n",
        "  dataframe.native_country= dataframe.native_country.astype(float)\n",
        "  dataframe.native_country = dataframe.native_country/dataframe.native_country.max()\n",
        "  dataframe.income.replace((' <=50K', ' >50K'),(0,1), inplace=True,regex=True)\n",
        "  dataframe.fnlwgt = dataframe.fnlwgt/dataframe.fnlwgt.max()\n",
        "  dataframe.education_num = dataframe.education_num/dataframe.education_num.max()\n",
        "  dataframe.hours_per_week = dataframe.hours_per_week/dataframe.hours_per_week.max()\n",
        "  dataframe.capital_gain = dataframe.capital_gain/dataframe.capital_gain.max()\n",
        "  dataframe.capital_loss = dataframe.capital_loss/dataframe.capital_loss.max()\n",
        "  return dataframe\n"
      ],
      "metadata": {
        "id": "bXWTghEybO16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pipeline and data processing \n",
        "def pipeline_and_prosessor(data_loader_type):\n",
        "  sample = iter(data_loader_type)\n",
        "  bacth = sample.next()\n",
        "  df_data_type_data = pd.DataFrame.from_dict(bacth)\n",
        "  prosessed_data_type = processing_data(df_data_type_data)\n",
        "  return prosessed_data_type"
      ],
      "metadata": {
        "id": "gJKOwhwFYkpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "class income_prediction(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size_1,hidden_size_2,output_size):\n",
        "    super(income_prediction,self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.leaky_ReLu = nn.LeakyReLU()#activation function\n",
        "    self.lin1 = nn.Linear(input_size, hidden_size_1)#inputlayer\n",
        "    self.lin2 = nn.Linear(hidden_size_1,hidden_size_2)#hiddenlayer\n",
        "    self.lin_out = nn.Linear(hidden_size_2,1)#outputlayer\n",
        "\n",
        "  def forward(self,x):\n",
        "      out = self.lin1(x)\n",
        "      out = self.leaky_ReLu(out)#activation function\n",
        "      out = self.lin2(out)\n",
        "      out = self.leaky_ReLu(out)#activation function\n",
        "      out = self.lin_out(out)\n",
        "      out = self.sigmoid(out)\n",
        "      return out\n",
        "\n",
        "model = income_prediction(input_size, hidden_size_1,hidden_size_2, output_size).to(device)"
      ],
      "metadata": {
        "id": "k1l5nhC_y7G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ],
      "metadata": {
        "id": "-vpjFDZbTH-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "n_steps = len(train_loader)\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(epoch_size):\n",
        "  for i in range(n_steps):\n",
        "    variables = pipeline_and_prosessor(train_loader)\n",
        "    variables = variables.T.drop(\"index\")\n",
        "    income = variables.iloc[14].values\n",
        "    inputs = variables.drop(\"income\").values\n",
        "    income = torch.Tensor(income)\n",
        "    inputs = torch.Tensor(inputs.T)\n",
        "\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(inputs)\n",
        "    outputs = outputs.view(-1)\n",
        "    loss = loss_func(outputs,income)\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    if (i + 1) % 163/2 == 0:\n",
        "      print(f\"epoch {epoch+1} / {epoch_size}, step {i+1} / {n_steps}, loss = {loss.item():.3f}\")\n",
        "      \n",
        "print(\"Done!\")\n",
        "end = time.time()\n"
      ],
      "metadata": {
        "id": "m7e44BzByPK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "531aeb8e-3faf-4f01-abdc-3ca4b11c6f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 5, step 163 / 163, loss = 0.476\n",
            "epoch 2 / 5, step 163 / 163, loss = 0.427\n",
            "epoch 3 / 5, step 163 / 163, loss = 0.395\n",
            "epoch 4 / 5, step 163 / 163, loss = 0.349\n",
            "epoch 5 / 5, step 163 / 163, loss = 0.373\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_tot_samples = 0\n",
        "  n_samples = len(test_loader)\n",
        "\n",
        "  for i in range(n_samples): #bytt til bake til n_samples    \n",
        "    variables = pipeline_and_prosessor(test_loader)\n",
        "    n_tot_samples += len(variables)\n",
        "    variables = variables.T.drop(\"index\")\n",
        "    income = variables.iloc[14].values\n",
        "    inputs = variables.drop(\"income\").values\n",
        "    income = torch.Tensor(income)\n",
        "    inputs = torch.Tensor(inputs.T)\n",
        "\n",
        "    pred = model(inputs)\n",
        "    \n",
        "    \n",
        "    for j in range(len(pred)):\n",
        "      if pred[j].item() < 0.5:\n",
        "          temp_pred = 0\n",
        "      else:\n",
        "          temp_pred = 1\n",
        "      n_correct += (temp_pred == income[j].item())\n",
        "\n",
        "  acc = n_correct/n_tot_samples * 100 \n",
        "\n",
        "  print(f\"Acc = {acc:.3f}%\")\n",
        "  print(f\"Time = {round(end - start,3)} sek\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwcUikf4vCW4",
        "outputId": "a1928e0c-fd69-472f-9708-826371dbc47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc = 80.271%\n",
            "Time = 109.992 sek\n"
          ]
        }
      ]
    }
  ]
}